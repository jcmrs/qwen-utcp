{
  "repository": "agent-implementation-example",
  "commit_hash": "01b785e2884a5234c7d56527eda020355dff59b1",
  "commit_timestamp": "1753280658",
  "file_count": 11,
  "extractions": [
    {
      "file_path": "UPSTREAM\\agent-implementation-example\\agent.py",
      "content_type": "code",
      "content": "\"\"\"\nUTCP OpenAI Integration Example\n\nThis example demonstrates how to:\n1. Initialize a UTCP client with tool providers from a config file\n2. For each user request, search for relevant tools.\n3. Instruct OpenAI to respond with a JSON for a tool call.\n4. Parse the JSON and execute the tool call using the UTCP client.\n5. Return the results to OpenAI for a final response.\n\"\"\"\n\nimport json\nimport re\nfrom typing import Dict, Any, List\n\nimport openai\n\nfrom utcp.client.utcp_client import UtcpClient\nfrom utcp.shared.tool import Tool\n\nclass Agent:\n    def __init__(self, utcp_client: UtcpClient, openai_client: openai.AsyncOpenAI):\n        self.utcp_client = utcp_client\n        self.openai_client = openai_client\n        self.conversation_history = []\n\n    async def _get_openai_response(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Get a response from OpenAI.\"\"\"\n        response = await self.openai_client.chat.completions.create(\n            model=\"gpt-4o-mini\",\n            messages=messages,\n        )\n        return response.choices[0].message.content\n\n    def _format_tools_for_prompt(self, tools: List[Tool]) -> str:\n        \"\"\"Convert UTCP tools to a JSON string for the prompt.\"\"\"\n        tool_list = []\n        for tool in tools:\n            tool_list.append(tool.model_dump())\n        return json.dumps(tool_list, indent=2)\n\n    async def chat(self, user_prompt: str, depth: int = 0):\n        if depth > 2:\n            return\n        \n        current_task = await self._get_openai_response(\n            self.conversation_history + [\n                {\"role\": \"user\", \"content\": user_prompt},\n                {\"role\": \"user\", \"content\": \"Based on this message history, what is the current task?\\n\\n\"}\n            ]\n        )\n        print(\"\\nSearching for relevant tools for task: \" + current_task)\n        relevant_tools = await self.utcp_client.search_tools(current_task, limit=10)\n        \n        if relevant_tools:\n            print(f\"Found {len(relevant_tools)} relevant tools.\")\n            for tool in relevant_tools:\n                print(f\"- {tool.name}\")\n        else:\n            print(\"No relevant tools found.\")\n\n        tools_json_string = self._format_tools_for_prompt(relevant_tools)\n\n        answer_tool = json.dumps({'tool_name': 'answer', 'arguments': {'text': 'your answer here'}})\n\n        system_prompt = (\n            \"You are a helpful assistant. When you need to use a tool, you MUST respond with a JSON object \"\n            \"with 'tool_name' and 'arguments' keys. Do not add any other text. The arguments must be a JSON object.\"\n            \"For example: {\\\"tool_name\\\": \\\"some_tool.name\\\", \\\"arguments\\\": {\\\"arg1\\\": \\\"value1\\\"}}. \"\n            f\"You will receive a list of the most relevant tools, based on the user query.\"\n            \"If you want to answer the user, you have a special tool called 'answer'.\"\n            f\"To use it, simply write {answer_tool}.\"\n        )\n        \n        messages = [\n            {\"role\": \"system\", \"content\": system_prompt},\n        ]\n        if self.conversation_history:\n            messages.extend(self.conversation_history)\n        user_prompt_and_tools = user_prompt + f\"\\n\\nRelevant tools:\\n{answer_tool}\\n{tools_json_string}\"\n        self.conversation_history.append({\"role\": \"user\", \"content\": user_prompt})\n        messages.append({\"role\": \"user\", \"content\": user_prompt_and_tools})\n\n        print(\"\\nSending request to OpenAI...\")\n        assistant_response = await self._get_openai_response(messages)\n        self.conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n\n        json_match = re.search(r'```json\\n({.*?})\\n```', assistant_response, re.DOTALL)\n        if not json_match:\n            json_match = re.search(r'({.*})', assistant_response, re.DOTALL)\n\n        if json_match:\n            json_string = json_match.group(1)\n            try:\n                tool_call_data = json.loads(json_string)\n                if \"tool_name\" in tool_call_data and \"arguments\" in tool_call_data:\n                    tool_name = tool_call_data[\"tool_name\"]\n                    arguments = tool_call_data[\"arguments\"]\n                    \n                    if tool_name == \"answer\":\n                        print(f\"\\nAssistant: {arguments['text']}\")\n                        return\n\n                    print(f\"\\nExecuting tool call: {tool_name}\")\n                    print(f\"Arguments: {json.dumps(arguments, indent=2)}\")\n\n                    try:\n                        result = await self.utcp_client.call_tool(tool_name, arguments)\n                        print(f\"Result: {result}\")\n                        tool_output = str(result)\n                    except Exception as e:\n                        error_message = f\"Error calling {tool_name}: {str(e)}\"\n                        print(f\"Error: {error_message}\")\n                        tool_output = error_message\n\n                    # Add user prompt and assistant's response to history\n                    await self.chat(f\"Explain the tool results to the user in plain text.\\nTool results: {tool_output}\", depth + 1)\n                else:\n                    await self.chat(f\"Wrong tool call format: {tool_call_data}\", depth + 1)\n            except json.JSONDecodeError as e:\n                await self.chat(f\"JSONDecodeError: {json_string}\", depth + 1)\n        else:\n            await self.chat(f\"No json in agents response: {assistant_response}\", depth + 1)\n",
      "line_count": 124,
      "word_count": 490,
      "title": "Agent.Py",
      "summary": "UTCP OpenAI Integration Example This example demonstrates how to:",
      "key_terms": [
        "chat",
        "Result",
        "role",
        "search",
        "async",
        "each",
        "If",
        "based",
        "list",
        "receive",
        "format",
        "Utcp",
        "MUST",
        "providers",
        "Found",
        "must",
        "found",
        "other",
        "string",
        "Error"
      ],
      "timestamp": "2025-12-24T18:55:58.204192"
    },
    {
      "file_path": "UPSTREAM\\agent-implementation-example\\embedding_model.py",
      "content_type": "code",
      "content": "\"\"\"\nLocal embedding model implementation using all-MiniLM-L6-v2.\n\"\"\"\nfrom typing import List\nfrom langchain_huggingface import HuggingFaceEmbeddings\n\nclass EmbeddingModel:\n    \"\"\"\n    Local embedding model using all-MiniLM-L6-v2 from HuggingFace.\n    \"\"\"\n    \n    def __init__(self,\n                 api_key: str = None,\n                 model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n        \"\"\"\n        Initialize the embedding model.\n        \n        Args:\n            api_key: Not used for local models, kept for compatibility\n            model_name: The embedding model to use (default: \"sentence-transformers/all-MiniLM-L6-v2\")\n        \"\"\"\n        self.model_name = model_name\n        \n        # Initialize the local HuggingFace embedding model\n        self.model = HuggingFaceEmbeddings(\n            model_name=self.model_name,\n            model_kwargs={'device': 'cpu'},  # Use CPU for compatibility\n            encode_kwargs={'normalize_embeddings': True}  # Normalize for better similarity\n        )\n    \n    async def embed(self, text: str) -> List[float]:\n        \"\"\"\n        Generate embedding for a single text.\n        \n        Args:\n            text: The text to embed\n            \n        Returns:\n            A float array representing the embedding\n        \"\"\"\n        # Run in thread pool to avoid blocking the event loop\n        import asyncio\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(None, self.model.embed_query, text)\n    \n    async def embed_batch(self, texts: List[str]) -> List[List[float]]:\n        \"\"\"\n        Generate embeddings for multiple texts using local model.\n        \n        Args:\n            texts: List of texts to embed\n            \n        Returns:\n            List of float arrays representing the embeddings\n        \"\"\"\n        if not texts:\n            return []\n        \n        # Run in thread pool to avoid blocking the event loop\n        import asyncio\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(None, self.model.embed_documents, texts)\n",
      "line_count": 63,
      "word_count": 197,
      "title": "Embedding Model.Py",
      "summary": "Local embedding model implementation using all-MiniLM-L6-v2. from typing import List",
      "key_terms": [
        "compatibility",
        "arrays",
        "from",
        "EmbeddingModel",
        "async",
        "None",
        "def",
        "transformers",
        "loop",
        "device",
        "HuggingFace",
        "Generate",
        "pool",
        "Initialize",
        "sentence",
        "float",
        "Not",
        "for",
        "default",
        "Local"
      ],
      "timestamp": "2025-12-24T18:55:58.225074"
    },
    {
      "file_path": "UPSTREAM\\agent-implementation-example\\main.py",
      "content_type": "code",
      "content": "import asyncio\nimport uuid\nfrom typing import Optional, Dict, List, Literal\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel, Field\nfrom enum import Enum\nfrom agent import Agent\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nimport os\nimport sys\nimport openai\nfrom utcp.client.utcp_client_config import UtcpClientConfig, UtcpDotEnv\nfrom utcp.client.utcp_client import UtcpClient\nfrom vector_store import EmbeddingInMemRepo\nfrom embedding_model import EmbeddingModel\nfrom tool_selector import ToolSelector\nfrom tag_analyzer import TagAnalyzer\nfrom utcp.shared.utcp_manual import UtcpManual\nfrom utcp.shared.tool import utcp_tool\nfrom utcp.shared.provider import HttpProvider\nimport aiohttp\nfrom utcp.shared.tool import ToolInputOutputSchema\nfrom pydantic.json_schema import GenerateJsonSchema\n\nload_dotenv(Path(__file__).parent / \".env\")\n\nif not os.environ.get(\"OPENAI_API_KEY\"):\n    print(\"Error: OPENAI_API_KEY not found in environment variables\")\n    print(\"Please set it in the .env file\")\n    sys.exit(1)\n\nproviders_file_path = str(Path(__file__).parent / \"providers.json\")\n\napi_key = os.environ.get(\"OPENAI_API_KEY\")\n\n# Create a configuration for the UTCP client\nconfig = UtcpClientConfig(\n    providers_file_path=providers_file_path,\n    load_variables_from=[\n        UtcpDotEnv(env_file_path=str(Path(__file__).parent / \".env\"))\n    ]\n)\nopenai_client = openai.AsyncOpenAI(api_key=api_key)\n\nembedding_model = EmbeddingModel(api_key=api_key)\ntool_repo = EmbeddingInMemRepo(embedding_model)\ntool_search_strategy = ToolSelector(tool_repo, embedding_model, TagAnalyzer(openai_client=openai_client))\nutcp_client = None\nagent = None\n\n# FastAPI app setup\n__version__ = \"1.0.0\"\nBASE_PATH = \"http://localhost:1646\"\n\napp = FastAPI(title=\"UTCP Agent API\", version=__version__)\n\nclass RegisterProviderResponse(BaseModel):\n    success: bool\n    message: str\n    provider_name: str\n\ngenerator = GenerateJsonSchema()\nresolved_schema = generator.generate(HttpProvider.__pydantic_core_schema__)\nresolved_schema = generator.resolve_ref_schema(resolved_schema)\nresolved_schema[\"required\"] = [\"name\", \"url\"]\ntool_schema = ToolInputOutputSchema(\n    properties={\"provider\": resolved_schema},\n    required=[\"provider\"],\n    title=\"Register Provider\"\n)\n\n@utcp_tool(\n    tool_provider=HttpProvider(\n        name=\"utcp_agent\",\n        http_method=\"POST\",\n        url=\"http://localhost:1646/register-provider\",\n        body_field=\"provider\"\n    ),\n    tags=[\"Register\", \"Tools\", \"New Provider\", \"HTTP\", \"Provider\", \"Manual\", \"OpenAPI\", \"UTCP\", \"UTCP Agent\"],\n    description=\"Register a new HTTP tool provider for yourself\",\n    inputs=tool_schema\n)\n@app.post(\"/register-provider\", response_model=RegisterProviderResponse)\nasync def register_http_provider(provider: HttpProvider) -> RegisterProviderResponse:\n    \"\"\"Register an HTTP tool provider with the UTCP client\"\"\"\n    global utcp_client\n    \n    if utcp_client is None:\n        raise HTTPException(status_code=500, detail=\"UTCP client not initialized\")\n    \n    try:\n        # Register the provider with the UTCP client\n        await utcp_client.register_tool_provider(provider)\n        \n        return RegisterProviderResponse(\n            success=True,\n            message=f\"HTTP provider '{provider.name}' registered successfully\",\n            provider_name=provider.name\n        )\n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to register provider: {str(e)}\"\n        )\n\n# API endpoints\n@app.get(\"/utcp\", response_model=UtcpManual)\ndef get_utcp():\n    \"\"\"Get UTCP manual information\"\"\"\n    manual = UtcpManual.create(version=__version__)\n    return manual\n\n@app.get(\"/health\")\ndef health_check():\n    \"\"\"Health check endpoint\"\"\"\n    return {\"status\": \"healthy\", \"version\": __version__}\n\nasync def wait_for_server_ready(max_attempts=30, delay=1):\n    \"\"\"Wait for the FastAPI server to be ready\"\"\"\n    for attempt in range(max_attempts):\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.get(f\"{BASE_PATH}/health\") as response:\n                    if response.status == 200:\n                        return True\n        except Exception:\n            pass\n        await asyncio.sleep(delay)\n    return False\n\nasync def run_interactive_agent():\n    \"\"\"Run the interactive agent in a separate task\"\"\"\n    global utcp_client, agent\n    \n    # Wait for server to be ready\n    print(\"Waiting for server to start...\")\n    if await wait_for_server_ready():\n        print(\"Server is ready!\")\n    else:\n        print(\"Warning: Server may not be fully ready\")\n    \n    # Initialize UTCP client first\n    utcp_client = await UtcpClient.create(config, tool_repository=tool_repo, search_strategy=tool_search_strategy)\n    agent = Agent(utcp_client, openai_client)\n    \n    print(\"\\n=== Interactive Agent Started ===\")\n    print(\"The agent now has access to itself via the API at http://localhost:1646\")\n    print(\"You can register HTTP providers via POST /register-provider\")\n    print(\"Available endpoints:\")\n    print(\"  - GET /utcp (UTCP manual)\")\n    print(\"  - POST /register-provider (Register HTTP provider)\")\n    print(\"  - GET /health (Health check)\")\n    print(\"Type 'exit' or 'quit' to stop\\n\")\n    \n    while True:\n        try:\n            user_prompt = await asyncio.get_event_loop().run_in_executor(None, input, \"User: \")\n            \n            if user_prompt.lower() in [\"exit\", \"quit\"]:\n                print(\"Shutting down...\")\n                break\n\n            await agent.chat(user_prompt)\n        except KeyboardInterrupt:\n            print(\"\\nShutting down...\")\n            break\n        except Exception as e:\n            print(f\"Error in agent chat: {e}\")\n\nasync def run_server():\n    \"\"\"Run the FastAPI server\"\"\"\n    import uvicorn\n    config = uvicorn.Config(app, host=\"localhost\", port=1646, log_level=\"info\")\n    server = uvicorn.Server(config)\n    await server.serve()\n\nasync def main():\n    \"\"\"Main function to run both FastAPI server and interactive agent\"\"\"\n\n    # Run both server and interactive agent concurrently\n    await asyncio.gather(\n        run_server(),\n        run_interactive_agent()\n    )\n\nif __name__ == \"__main__\":\n    try:\n        asyncio.run(main())\n    except KeyboardInterrupt:\n        print(\"\\nApplication stopped by user\")\n",
      "line_count": 192,
      "word_count": 560,
      "title": "Main.Py",
      "summary": "import asyncio import uuid",
      "key_terms": [
        "lower",
        "chat",
        "async",
        "localhost",
        "Type",
        "check",
        "Available",
        "info",
        "Utcp",
        "providers",
        "GenerateJsonSchema",
        "found",
        "global",
        "Error",
        "except",
        "gather",
        "task",
        "shared",
        "has",
        "AsyncOpenAI"
      ],
      "timestamp": "2025-12-24T18:55:58.267525"
    },
    {
      "file_path": "UPSTREAM\\agent-implementation-example\\providers copy.json",
      "content_type": "configuration",
      "content": "[\n    {\n        \"name\": \"openlibrary\",\n        \"provider_type\": \"http\",\n        \"http_method\": \"GET\",\n        \"url\": \"https://openlibrary.org/static/openapi.json\",\n        \"content_type\": \"application/json\"\n    },\n    {\n        \"name\": \"newsapi\",\n        \"provider_type\": \"text\",\n        \"file_path\": \"./text_manuals/newsapi_manual.json\"\n    },\n    {\n        \"name\": \"openai\",\n        \"provider_type\": \"http\",\n        \"http_method\": \"GET\",\n        \"url\": \"https://raw.githubusercontent.com/openai/openai-openapi/refs/heads/manual_spec/openapi.yaml\",\n        \"content_type\": \"application/x-yaml\"\n    },\n    {\n        \"name\": \"utcp_agent\",\n        \"provider_type\": \"http\",\n        \"http_method\": \"GET\",\n        \"url\": \"http://localhost:1646/utcp\",\n        \"content_type\": \"application/json\"\n    }\n]",
      "line_count": 28,
      "word_count": 46,
      "title": "Providers Copy.Json",
      "summary": "\"name\": \"openlibrary\", \"provider_type\": \"http\",",
      "key_terms": [
        "openai-openapi",
        "yaml",
        "localhost",
        "raw",
        "static",
        "utcp",
        "heads",
        "method",
        "url",
        "GET",
        "newsapi",
        "openlibrary",
        "application",
        "openai",
        "name",
        "https",
        "x-yaml",
        "githubusercontent",
        "com",
        "http"
      ],
      "timestamp": "2025-12-24T18:55:58.286428"
    },
    {
      "file_path": "UPSTREAM\\agent-implementation-example\\providers.json",
      "content_type": "configuration",
      "content": "[\n    {\n        \"name\": \"newsapi\",\n        \"provider_type\": \"text\",\n        \"file_path\": \"./text_manuals/newsapi_manual.json\"\n    },\n    {\n        \"name\": \"utcp_agent\",\n        \"provider_type\": \"http\",\n        \"http_method\": \"GET\",\n        \"url\": \"http://localhost:1646/utcp\",\n        \"content_type\": \"application/json\"\n    }\n]",
      "line_count": 14,
      "word_count": 22,
      "title": "Providers.Json",
      "summary": "\"name\": \"newsapi\", \"provider_type\": \"text\",",
      "key_terms": [
        "url",
        "GET",
        "utcp",
        "text",
        "api",
        "localhost",
        "json",
        "newsapi",
        "application",
        "method",
        "http",
        "name"
      ],
      "timestamp": "2025-12-24T18:55:58.315869"
    },
    {
      "file_path": "UPSTREAM\\agent-implementation-example\\README.md",
      "content_type": "documentation",
      "content": "# UTCP Agent\n\nAn example implementation of the Universal Tool Calling Protocol (UTCP) that demonstrates how to build an agentic assistant capable of discovering, selecting, and using tools from multiple providers.\n\n## Overview\n\nThis repository showcases how the Universal Tool Calling Protocol (UTCP) makes agentic tool calling simpler and more powerful. With UTCP, agents can discover and use external tools by interacting with them directly via their native protocols, eliminating the need for custom wrappers around each tool.\n\nThe agent can:\n- Load tool providers from configuration files\n- Register new tool providers via natural language instructions\n- Search for the most relevant tools based on user queries\n- Execute tool calls and return results to the user\n\n## Getting Started\n\n### Prerequisites\n\n- Python 3.8+\n- OpenAI API key\n\n### Installation\n\n1. Clone this repository\n2. Install dependencies:\n   ```\n   pip install -r requirements.txt\n   ```\n3. Create a `.env` file in the root directory with your OpenAI API key:\n   ```\n   OPENAI_API_KEY=your_api_key_here\n   ```\n\n### Running the Agent\n\nStart the agent with:\n\n```\npython main.py\n```\n\nThis will:\n1. Start a FastAPI server on http://localhost:1646\n2. Initialize the UTCP client and load providers from `providers.json`\n3. Start the interactive CLI agent\n\n## Using the Agent\n\nThe agent supports:\n\n1. **Natural language queries**: Ask the agent questions and it will find and use the most relevant tools.\n2. **Tool registration**: Tell the agent to register a new tool provider by URL or manual specification.\n\nExample interactions:\n```\nUser: What's the latest news about AI?\nAgent: Let me check the latest news for you...\n[Agent uses newsapi tool to retrieve information]\n\nUser: Register a weather API at https://api.weather.com/utcp\nAgent: I'll register this weather API provider for you...\n[Agent registers the new provider and confirms]\n\nUser: What's the weather in New York?\nAgent: Let me check the weather in New York...\n[Agent uses newly registered weather API tool]\n```\n\n## Tool Provider Configuration\n\nTool providers are configured in `providers.json`. Example providers:\n\n```json\n[\n    {\n        \"name\": \"newsapi\",\n        \"provider_type\": \"text\",\n        \"file_path\": \"./text_manuals/newsapi_manual.json\"\n    },\n    {\n        \"name\": \"utcp_agent\",\n        \"provider_type\": \"http\",\n        \"http_method\": \"GET\",\n        \"url\": \"http://localhost:1646/utcp\",\n        \"content_type\": \"application/json\"\n    }\n]\n```\n\n## Key Components\n\n### Core Components\n\n- **Agent** (`agent.py`): Manages conversations with users, searches for relevant tools, and uses OpenAI to generate responses and tool calls.\n- **UTCP Client**: Handles tool provider registration, tool discovery, and tool execution.\n\n### Tool Discovery and Selection\n\n- **EmbeddingModel** (`embedding_model.py`): Local embedding model using all-MiniLM-L6-v2 from HuggingFace for generating vector representations of tools and queries.\n- **TagAnalyzer** (`tag_analyzer.py`): Extracts relevant tags from user queries using OpenAI to improve tool search relevance.\n- **ToolSelector** (`tool_selector.py`): Implements the UTCP `ToolSearchStrategy` to find the most appropriate tools based on embedding similarity and tag matching.\n- **EmbeddingInMemRepo** (`vector_store.py`): In-memory implementation of the UTCP `ToolRepository` interface that stores tools and their embeddings.\n\n### Server and API\n\n- **FastAPI Server** (`main.py`): Provides endpoints for health checks, the UTCP manual, and registering new HTTP providers.\n- **Interactive CLI**: Allows users to chat with the agent directly via the command line.\n\n## About UTCP\n\nThe Universal Tool Calling Protocol (UTCP) is a specification that enables applications to discover and use external tools by interacting with them directly via their native protocols. Key benefits:\n\n- **No wrapper tax**: Call any tool without changes to the tool itself\n- **Native security**: Leverage existing security mechanisms\n- **Scalable**: Handle a large number of tools and calls\n- **Simple**: Easy to implement and use\n\nFor more information about UTCP, visit the [UTCP documentation](https://utcp.io).\n\n## License\n\nApache License 2.0\n\n## [Contributors](https://utcp.io/about)",
      "line_count": 124,
      "word_count": 584,
      "title": "UTCP Agent",
      "summary": "An example implementation of the Universal Tool Calling Protocol (UTCP) that demonstrates how to build an agentic assistant capable of discovering, selecting, and using tools from multiple providers. ...",
      "key_terms": [
        "Natural",
        "chat",
        "build",
        "Python",
        "search",
        "number",
        "localhost",
        "each",
        "based",
        "check",
        "Clone",
        "uses",
        "dependencies",
        "generating",
        "me",
        "providers",
        "natural",
        "Scalable",
        "AI",
        "multiple"
      ],
      "timestamp": "2025-12-24T18:55:58.347461"
    },
    {
      "file_path": "UPSTREAM\\agent-implementation-example\\requirements.txt",
      "content_type": "other",
      "content": "utcp\n\nopenai\nlangchain\nlangchain-openai\nlangchain-huggingface\nsentence-transformers\npython-dotenv\nnumpy\nfastapi\nuvicorn[standard]\naiohttp\njsonref",
      "line_count": 13,
      "word_count": 12,
      "title": "Requirements.Txt",
      "summary": "langchain-openai langchain-huggingface",
      "key_terms": [
        "uvicorn",
        "jsonref",
        "transformers",
        "utcp",
        "numpy",
        "sentence",
        "huggingface",
        "aiohttp",
        "langchain-huggingface",
        "openai",
        "langchain",
        "python",
        "fastapi",
        "dotenv",
        "langchain-openai",
        "api",
        "standard",
        "python-dotenv",
        "sentence-transformers"
      ],
      "timestamp": "2025-12-24T18:55:58.375736"
    },
    {
      "file_path": "UPSTREAM\\agent-implementation-example\\tag_analyzer.py",
      "content_type": "code",
      "content": "\"\"\"\nTag analyzer for extracting and matching tags from user queries.\n\"\"\"\nfrom typing import List, Dict, Any\nimport openai\n\nclass TagAnalyzer:\n    \"\"\"\n    Class for extracting and analyzing tags from user queries.\n    \"\"\"\n    \n    def __init__(self, openai_client: openai.AsyncOpenAI):\n        \"\"\"\n        Initialize the tag analyzer.\n        \n        Args:\n            openai_client: The OpenAI client to use for tag analysis\n        \"\"\"\n        self.client = openai_client\n    \n    async def extract_tags(self, query: str, available_tags: List[str]) -> List[str]:\n        \"\"\"\n        Extract relevant tags from a user query based on available tags.\n        \n        Args:\n            query: The user query\n            available_tags: List of all available tags in the database\n            \n        Returns:\n            List of relevant tags extracted from the query\n        \"\"\"\n        if not available_tags:\n            return []\n        \n        # Format the tag list for the prompt\n        tags_str = \", \".join(available_tags)\n        \n        # Create prompt for the LLM\n        prompt = f\"\"\"Given a user query and a list of available tags, identify the most relevant tags that match the query.\n        \nUser query: \"{query}\"\n\nAvailable tags: {tags_str}\n\nReturn a JSON array of the most relevant tags (maximum 5 tags). Only return tags that are in the available tags list.\nJust return the JSON array with no other text. If no relevant tags are found, return an empty array.\n\nOutput:\"\"\"\n        \n        # Get tags from the LLM\n        response = await self.client.chat.completions.create(\n            model=\"gpt-4o-mini\",\n            messages=[\n                {\"role\": \"system\", \"content\": prompt},\n                {\"role\": \"user\", \"content\": query}\n            ]\n        )\n        \n        # Parse the response to extract tags\n        # Clean up the response to ensure it's valid JSON\n        response = response.choices[0].message.content.strip()\n        if response.startswith(\"```json\"):\n            response = response[7:]\n        if response.endswith(\"```\"):\n            response = response[:-3]\n        response = response.strip()\n        \n        try:\n            import json\n            tags = json.loads(response)\n            # Ensure we only return tags that are actually in the available_tags\n            validated_tags = [tag for tag in tags if tag in available_tags]\n            return validated_tags\n        except Exception as e:\n            print(f\"Error parsing tags from LLM response: {e}\")\n            print(f\"LLM response: {response}\")\n            return []\n",
      "line_count": 78,
      "word_count": 295,
      "title": "Tag Analyzer.Py",
      "summary": "Tag analyzer for extracting and matching tags from user queries. from typing import List, Dict, Any",
      "key_terms": [
        "chat",
        "we",
        "up",
        "role",
        "extract",
        "async",
        "If",
        "analyzer",
        "based",
        "list",
        "Available",
        "endswith",
        "available",
        "only",
        "found",
        "other",
        "Error",
        "choices",
        "except",
        "AsyncOpenAI"
      ],
      "timestamp": "2025-12-24T18:55:58.395210"
    },
    {
      "file_path": "UPSTREAM\\agent-implementation-example\\tool_selector.py",
      "content_type": "code",
      "content": "\"\"\"\nTool selector module for finding the most appropriate tools based on user queries.\n\"\"\"\nfrom typing import List, Dict, Any, Tuple, Set\nfrom abc import ABC, abstractmethod\nfrom vector_store import EmbeddingInMemRepo\nfrom embedding_model import EmbeddingModel\nfrom tag_analyzer import TagAnalyzer\nfrom utcp.shared.tool import Tool\nfrom utcp.client.tool_search_strategy import ToolSearchStrategy\n\nclass ToolSelector(ToolSearchStrategy):\n    \"\"\"\n    Class for selecting the most appropriate tools based on user queries.\n    \"\"\"\n    \n    def __init__(self, vector_store: EmbeddingInMemRepo, embedding_model: EmbeddingModel, tag_analyzer: TagAnalyzer):\n        \"\"\"\n        Initialize the tool selector.\n        \n        Args:\n            vector_store: The vector store for tool lookup\n            embedding_model: The embedding model for generating embeddings\n            tag_analyzer: The tag analyzer for extracting tags from queries\n        \"\"\"\n        self.vector_store = vector_store\n        self.embedding_model = embedding_model\n        self.tag_analyzer = tag_analyzer\n    \n    async def search_tools(self, query: str, limit: int = 10) -> List[Tool]:\n        \"\"\"\n        Search for tools relevant to the query.\n\n        Args:\n            query: The search query.\n            limit: The maximum number of tools to return. 0 for no limit.\n\n        Returns:\n            A list of tools that match the search query.\n        \"\"\"\n        # Get all available tags\n        available_tags = self.vector_store.get_all_tags()\n        \n        # Strategy 1: Extract relevant tags from query\n        relevant_tags = await self.tag_analyzer.extract_tags(query, available_tags)\n        \n        # Strategy 2: Generate embedding for the query\n        query_embedding = await self.embedding_model.embed(query)\n        \n        # Perform searches using both strategies\n        # Strategy 1 result: Search by tags\n        tag_results = await self.vector_store.search_by_tags(relevant_tags, top_k=limit if limit > 0 else 50)\n        \n        # Strategy 2 result: Search by embedding\n        embedding_results = await self.vector_store.search_by_embedding(query_embedding, top_k=limit if limit > 0 else 50)\n        \n        # Combine results from both strategies\n        # Use a set to track unique tools\n        unique_tools = set()\n        combined_results = []\n        \n        # First add tools from embedding search with their scores\n        for tool, score in embedding_results:\n            if tool.name not in unique_tools:\n                combined_results.append((tool, score, \"embedding\"))\n                unique_tools.add(tool.name)\n        \n        # Then add tools from tag search if not already added\n        for tool, score in tag_results:\n            if tool.name not in unique_tools:\n                combined_results.append((tool, score, \"tag\"))\n                unique_tools.add(tool.name)\n        \n        # Sort combined results by score (descending)\n        combined_results.sort(key=lambda x: x[1], reverse=True)\n        \n        # Return just the tools, limited to the specified limit\n        if limit > 0:\n            return [result[0] for result in combined_results[:limit]]\n        else:\n            return [result[0] for result in combined_results]\n    \n    async def find_tools(self, query: str, max_tools: int = 5) -> List[Tool]:\n        \"\"\"\n        Legacy method for backward compatibility.\n        Select the most appropriate tools for a user query using multiple strategies.\n        \n        Args:\n            query: The user query\n            max_tools: Maximum number of tools to return\n            \n        Returns:\n            List of selected tools\n        \"\"\"\n        return await self.search_tools(query, max_tools)\n    \n    def get_tool_summary(self, tools: List[Tool]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Generate a summary of tools for presenting to the agent.\n        \n        Args:\n            tools: List of tools\n            \n        Returns:\n            List of tool summary dictionaries\n        \"\"\"\n        summaries = []\n        \n        for tool in tools:\n            summary = {\n                \"name\": tool.name,\n                \"description\": tool.description,\n                \"tags\": tool.tags,\n                \"provider\": tool.tool_provider.name if tool.tool_provider else None,\n                \"provider_type\": tool.tool_provider.provider_type if tool.tool_provider else None,\n                # Include basic parameter information without full schema details\n                \"parameters\": list(tool.inputs.properties.keys()) if tool.inputs and tool.inputs.properties else [],\n                \"returns\": list(tool.outputs.properties.keys()) if tool.outputs and tool.outputs.properties else []\n            }\n            summaries.append(summary)\n        \n        return summaries\n",
      "line_count": 123,
      "word_count": 477,
      "title": "Tool Selector.Py",
      "summary": "Tool selector module for finding the most appropriate tools based on user queries. from typing import List, Dict, Any, Tuple, Set",
      "key_terms": [
        "async",
        "search",
        "number",
        "ABC",
        "analyzer",
        "abc",
        "based",
        "list",
        "selected",
        "available",
        "selector",
        "generating",
        "specified",
        "multiple",
        "embedding",
        "shared",
        "using",
        "most",
        "parameters",
        "model"
      ],
      "timestamp": "2025-12-24T18:55:58.427033"
    },
    {
      "file_path": "UPSTREAM\\agent-implementation-example\\vector_store.py",
      "content_type": "code",
      "content": "\"\"\"\nIn-memory tool repository implementation with embedding support.\n\"\"\"\nimport json\nfrom typing import List, Dict, Any, Optional, Tuple\nimport numpy as np\n\nfrom embedding_model import EmbeddingModel\nfrom utcp.shared.tool import Tool\nfrom utcp.shared.provider import ProviderUnion, Provider\nfrom utcp.client.tool_repository import ToolRepository\n\nclass EmbeddingInMemRepo(ToolRepository):\n    \"\"\"\n    In-memory tool repository with embedding support for tool search.\n    \"\"\"\n    \n    def __init__(self, embedding_model: EmbeddingModel):\n        \"\"\"\n        Initialize the in-memory tool repository.\n        \n        Args:\n            embedding_model: The embedding model for generating embeddings\n        \"\"\"\n        self.tools: List[Tool] = []\n        self.tool_per_provider: Dict[str, Tuple[Provider, List[Tool]]] = {}\n        self.embedding_model = embedding_model\n        self._tool_embeddings: Dict[str, List[float]] = {}  # tool_name -> embedding\n        self._all_tags: set = set()  # Cache of all unique tags\n    \n    async def save_provider_with_tools(self, provider: Provider, tools: List[Tool]) -> None:\n        \"\"\"\n        Save a provider and its tools in the repository.\n        \n        Args:\n            provider: The provider to save.\n            tools: The tools associated with the provider.\n        \"\"\"\n        # Remove existing tools for this provider if any\n        if provider.name in self.tool_per_provider:\n            await self.remove_provider(provider.name)\n        \n        # Add tools to main list and generate embeddings\n        # Try batch embedding first for better performance\n        try:\n            embed_texts = [f\"{tool.name} {tool.description} {' '.join(tool.tags)}\" for tool in tools]\n            embeddings = await self.embedding_model.embed_batch(embed_texts)\n            \n            # Store embeddings and update tags (skip empty embeddings from failed batch items)\n            for tool, embedding in zip(tools, embeddings):\n                if embedding:  # Only store non-empty embeddings\n                    self._tool_embeddings[tool.name] = embedding\n                self._all_tags.update(tool.tags)\n                \n        except Exception as e:\n            print(f\"Batch embedding failed, falling back to individual embeddings: {e}\")\n            # Fallback to individual embedding generation\n            for tool in tools:\n                try:\n                    embed_text = f\"{tool.name} {tool.description} {' '.join(tool.tags)}\"\n                    embedding = await self.embedding_model.embed(embed_text)\n                    self._tool_embeddings[tool.name] = embedding\n                    self._all_tags.update(tool.tags)\n                except Exception as embed_error:\n                    print(f\"Failed to generate embedding for tool {tool.name}: {embed_error}\")\n                    # Continue with other tools even if one fails\n        \n        self.tools.extend(tools)\n        self.tool_per_provider[provider.name] = (provider, tools)\n    \n    async def remove_provider(self, provider_name: str) -> None:\n        \"\"\"\n        Remove a provider and its tools from the repository.\n        \n        Args:\n            provider_name: The name of the provider to remove.\n            \n        Raises:\n            ValueError: If the provider is not found.\n        \"\"\"\n        if provider_name not in self.tool_per_provider:\n            raise ValueError(f\"Provider '{provider_name}' not found\")\n        \n        tools_to_remove = self.tool_per_provider[provider_name][1]\n        \n        # Remove tools from main list\n        self.tools = [tool for tool in self.tools if tool not in tools_to_remove]\n        \n        # Remove embeddings for these tools\n        for tool in tools_to_remove:\n            self._tool_embeddings.pop(tool.name, None)\n        \n        # Remove provider\n        self.tool_per_provider.pop(provider_name, None)\n        \n        # Rebuild tags cache\n        self._all_tags = set()\n        for tool in self.tools:\n            self._all_tags.update(tool.tags)\n    \n    async def remove_tool(self, tool_name: str) -> None:\n        \"\"\"\n        Remove a tool from the repository.\n        \n        Args:\n            tool_name: The name of the tool to remove.\n            \n        Raises:\n            ValueError: If the tool is not found.\n        \"\"\"\n        provider_name = tool_name.split(\".\")[0]\n        if provider_name not in self.tool_per_provider:\n            raise ValueError(f\"Provider '{provider_name}' not found\")\n        \n        # Find and remove tool from main list\n        new_tools = [tool for tool in self.tools if tool.name != tool_name]\n        if len(new_tools) == len(self.tools):\n            raise ValueError(f\"Tool '{tool_name}' not found\")\n        \n        self.tools = new_tools\n        \n        # Remove embedding\n        self._tool_embeddings.pop(tool_name, None)\n        \n        # Update provider's tool list\n        provider, provider_tools = self.tool_per_provider[provider_name]\n        new_provider_tools = [tool for tool in provider_tools if tool.name != tool_name]\n        self.tool_per_provider[provider_name] = (provider, new_provider_tools)\n        \n        # Rebuild tags cache\n        self._all_tags = set()\n        for tool in self.tools:\n            self._all_tags.update(tool.tags)\n    \n    async def get_tool(self, tool_name: str) -> Optional[Tool]:\n        \"\"\"\n        Get a tool from the repository.\n        \n        Args:\n            tool_name: The name of the tool to retrieve.\n            \n        Returns:\n            The tool if found, otherwise None.\n        \"\"\"\n        for tool in self.tools:\n            if tool.name == tool_name:\n                return tool\n        return None\n    \n    async def get_tools(self) -> List[Tool]:\n        \"\"\"\n        Get all tools from the repository.\n        \n        Returns:\n            List of all tools\n        \"\"\"\n        return self.tools\n    \n    async def get_tools_by_provider(self, provider_name: str) -> Optional[List[Tool]]:\n        \"\"\"\n        Get tools associated with a specific provider.\n        \n        Args:\n            provider_name: The name of the provider.\n            \n        Returns:\n            A list of tools associated with the provider, or None if the provider is not found.\n        \"\"\"\n        if provider_name not in self.tool_per_provider:\n            return None\n        return self.tool_per_provider[provider_name][1]\n    \n    async def get_provider(self, provider_name: str) -> Optional[Provider]:\n        \"\"\"\n        Get a provider from the repository.\n        \n        Args:\n            provider_name: The name of the provider to retrieve.\n            \n        Returns:\n            The provider if found, otherwise None.\n        \"\"\"\n        if provider_name not in self.tool_per_provider:\n            return None\n        return self.tool_per_provider[provider_name][0]\n    \n    async def get_providers(self) -> List[Provider]:\n        \"\"\"\n        Get all providers from the repository.\n        \n        Returns:\n            A list of providers.\n        \"\"\"\n        return [provider for provider, _ in self.tool_per_provider.values()]\n    \n    def get_all_tags(self) -> List[str]:\n        \"\"\"\n        Get all unique tags from the repository.\n        \n        Returns:\n            List of all unique tags\n        \"\"\"\n        return list(self._all_tags)\n    \n    def _cosine_similarity(self, v1: List[float], v2: List[float]) -> float:\n        \"\"\"Calculate cosine similarity between two vectors\"\"\"\n        vec1 = np.array(v1)\n        vec2 = np.array(v2)\n        dot_product = np.dot(vec1, vec2)\n        norm_v1 = np.linalg.norm(vec1)\n        norm_v2 = np.linalg.norm(vec2)\n        return dot_product / (norm_v1 * norm_v2)\n    \n    async def search_by_embedding(self, query_embedding: List[float], top_k: int = 5) -> List[Tuple[Tool, float]]:\n        \"\"\"\n        Search tools by embedding similarity.\n        \n        Args:\n            query_embedding: The query embedding\n            top_k: Maximum number of results to return\n            \n        Returns:\n            List of (Tool, similarity_score) tuples\n        \"\"\"\n        results = []\n        \n        for tool in self.tools:\n            if tool.name in self._tool_embeddings:\n                embedding = self._tool_embeddings[tool.name]\n                similarity = self._cosine_similarity(query_embedding, embedding)\n                results.append((tool, similarity))\n        \n        # Sort by similarity score in descending order\n        results.sort(key=lambda x: x[1], reverse=True)\n        return results[:top_k]\n    \n    # Legacy method for backward compatibility\n    def remove_tool_legacy(self, name: str) -> bool:\n        \"\"\"\n        Remove a tool from the store (legacy method).\n        \n        Args:\n            name: Name of the tool to remove\n            \n        Returns:\n            True if the tool was removed, False if not found\n        \"\"\"\n        try:\n            import asyncio\n            asyncio.create_task(self.remove_tool(name))\n            return True\n        except ValueError:\n            return False\n        except Exception:\n            return False\n    \n    async def search_by_tags(self, tags: List[str], top_k: int = 5) -> List[Tuple[Tool, float]]:\n        \"\"\"\n        Search tools by tag overlap (Jaccard similarity).\n        \n        Args:\n            tags: List of tags to search for\n            top_k: Maximum number of results to return\n            \n        Returns:\n            List of (tool, score) tuples, where score is the Jaccard similarity\n        \"\"\"\n        tools = await self.get_tools()\n        results = []\n        \n        for tool in tools:\n            # Calculate tag overlap score (proportion of searched tags that exist in this tool)\n            matching_tags = set(tags) & set(tool.tags)\n            if matching_tags:\n                # Score is a combination of tag match ratio and the number of matching tags\n                match_ratio = len(matching_tags) / len(tags)\n                tag_weight = len(matching_tags) / (len(tool.tags) + 1)  # +1 to avoid division by zero\n                score = (match_ratio + tag_weight) / 2\n                results.append((tool, score))\n        \n        # Sort by tag overlap score in descending order\n        results.sort(key=lambda x: x[1], reverse=True)\n        return results[:top_k]\n",
      "line_count": 284,
      "word_count": 988,
      "title": "Vector Store.Py",
      "summary": "In-memory tool repository implementation with embedding support. import json",
      "key_terms": [
        "proportion",
        "Fallback",
        "search",
        "async",
        "number",
        "If",
        "Calculate",
        "list",
        "pop",
        "generating",
        "providers",
        "found",
        "associated",
        "other",
        "Cache",
        "embedding",
        "except",
        "falling",
        "shared",
        "model"
      ],
      "timestamp": "2025-12-24T18:55:58.459985"
    },
    {
      "file_path": "UPSTREAM\\agent-implementation-example\\text_manuals\\newsapi_manual.json",
      "content_type": "configuration",
      "content": "{\n  \"version\": \"1.0\",\n  \"tools\": [\n    {\n      \"name\": \"everything_get\",\n      \"description\": \"Search through millions of articles from over 150,000 large and small news sources and blogs. This endpoint suits article discovery and analysis. It requires either a search query, a source, or a domain.\",\n      \"tags\": [\n        \"articles\"\n      ],\n      \"inputs\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"q\": {\n            \"type\": \"string\",\n            \"description\": \"Keywords or phrases to search for in the article title and body. Advanced search is supported. Max length: 500 chars.\"\n          },\n          \"searchIn\": {\n            \"type\": \"string\",\n            \"description\": \"The fields to restrict your q search to. Possible options: title, description, content. Multiple options can be specified by separating them with a comma.\"\n          },\n          \"sources\": {\n            \"type\": \"string\",\n            \"description\": \"A comma-seperated string of identifiers (maximum 20) for the news sources or blogs you want headlines from.\"\n          },\n          \"domains\": {\n            \"type\": \"string\",\n            \"description\": \"A comma-seperated string of domains (eg bbc.co.uk, techcrunch.com, engadget.com) to restrict the search to.\"\n          },\n          \"excludeDomains\": {\n            \"type\": \"string\",\n            \"description\": \"A comma-seperated string of domains (eg bbc.co.uk, techcrunch.com, engadget.com) to remove from the results.\"\n          },\n          \"from\": {\n            \"type\": \"string\",\n            \"description\": \"A date and optional time for the oldest article allowed. This should be in ISO 8601 format (e.g. 2025-07-09 or 2025-07-09T09:28:11)\"\n          },\n          \"to\": {\n            \"type\": \"string\",\n            \"description\": \"A date and optional time for the newest article allowed. This should be in ISO 8601 format (e.g. 2025-07-09 or 2025-07-09T09:28:11)\"\n          },\n          \"language\": {\n            \"type\": \"string\",\n            \"description\": \"The 2-letter ISO-639-1 code of the language you want to get headlines for.\"\n          },\n          \"sortBy\": {\n            \"type\": \"string\",\n            \"description\": \"The order to sort the articles in. Possible options: relevancy, popularity, publishedAt.\"\n          },\n          \"pageSize\": {\n            \"type\": \"integer\",\n            \"description\": \"The number of results to return per page. Maximum: 100.\"\n          },\n          \"page\": {\n            \"type\": \"integer\",\n            \"description\": \"Use this to page through the results.\"\n          }\n        },\n        \"required\": [\n          \"q\"\n        ]\n      },\n      \"outputs\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"status\": {\n            \"type\": \"string\",\n            \"description\": \"If the request was successful or not. Options: ok, error.\"\n          },\n          \"totalResults\": {\n            \"type\": \"integer\",\n            \"description\": \"The total number of results available for your request.\"\n          },\n          \"articles\": {\n            \"type\": \"array\",\n            \"description\": \"The results of the request.\",\n            \"items\": {\n              \"type\": \"object\",\n              \"properties\": {\n                \"source\": {\n                  \"type\": \"object\",\n                  \"description\": \"The identifier id and a display name name for the source this article came from.\",\n                  \"properties\": {\n                    \"id\": {\n                      \"type\": \"string\"\n                    },\n                    \"name\": {\n                      \"type\": \"string\"\n                    }\n                  }\n                },\n                \"author\": {\n                  \"type\": \"string\",\n                  \"description\": \"The author of the article\"\n                },\n                \"title\": {\n                  \"type\": \"string\",\n                  \"description\": \"The headline or title of the article.\"\n                },\n                \"description\": {\n                  \"type\": \"string\",\n                  \"description\": \"A description or snippet from the article.\"\n                },\n                \"url\": {\n                  \"type\": \"string\",\n                  \"description\": \"The direct URL to the article.\"\n                },\n                \"urlToImage\": {\n                  \"type\": \"string\",\n                  \"description\": \"The URL to a relevant image for the article.\"\n                },\n                \"publishedAt\": {\n                  \"type\": \"string\",\n                  \"description\": \"The date and time that the article was published, in UTC (+000)\"\n                },\n                \"content\": {\n                  \"type\": \"string\",\n                  \"description\": \"The unformatted content of the article, where available. This is truncated to 200 chars.\"\n                }\n              },\n              \"required\": [\n                \"title\"\n              ]\n            }\n          }\n        }\n      },\n      \"tool_provider\": {\n        \"provider_type\": \"http\",\n        \"url\": \"https://newsapi.org/v2/everything\",\n        \"http_method\": \"GET\",\n        \"content_type\": \"application/json\",\n        \"auth\": {\n          \"auth_type\": \"api_key\",\n          \"api_key\": \"$NEWS_API_KEY\",\n          \"var_name\": \"X-Api-Key\"\n        }\n      }\n    },\n    {\n      \"name\": \"top_headlines_get\",\n      \"description\": \"This endpoint provides live top and breaking headlines for a country, specific category in a country, single source, or multiple sources. You can also search with keywords. Articles are sorted by the earliest date published first. This endpoint is great for retrieving headlines for use with news tickers or similar.\",\n      \"tags\": [\n        \"articles\"\n      ],\n      \"inputs\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"country\": {\n            \"type\": \"string\",\n            \"description\": \"The 2-letter ISO 3166-1 code of the country you want to get headlines for. Note: you can't mix this param with the sources param.\"\n          },\n          \"category\": {\n            \"type\": \"string\",\n            \"description\": \"The category you want to get headlines for. Possible options: business, entertainment, general, health, science, sports, technology. Note: you can't mix this param with the sources param.\"\n          },\n          \"sources\": {\n            \"type\": \"string\",\n            \"description\": \"A comma-seperated string of identifiers for the news sources or blogs you want headlines from. Note: you can't mix this param with the country or category params.\"\n          },\n          \"q\": {\n            \"type\": \"string\",\n            \"description\": \"Keywords or a phrase to search for.\"\n          },\n          \"pageSize\": {\n            \"type\": \"integer\",\n            \"description\": \"The number of results to return per page (request). 20 is the default, 100 is the maximum.\"\n          },\n          \"page\": {\n            \"type\": \"integer\",\n            \"description\": \"Use this to page through the results if the total results found is greater than the page size.\"\n          }\n        }\n      },\n      \"outputs\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"status\": {\n            \"type\": \"string\",\n            \"description\": \"If the request was successful or not. Options: ok, error.\"\n          },\n          \"totalResults\": {\n            \"type\": \"integer\",\n            \"description\": \"The total number of results available for your request.\"\n          },\n          \"articles\": {\n            \"type\": \"array\",\n            \"description\": \"The results of the request.\",\n            \"items\": {\n              \"type\": \"object\",\n              \"properties\": {\n                \"source\": {\n                  \"type\": \"object\",\n                  \"description\": \"The identifier id and a display name name for the source this article came from.\",\n                  \"properties\": {\n                    \"id\": {\n                      \"type\": \"string\"\n                    },\n                    \"name\": {\n                      \"type\": \"string\"\n                    }\n                  }\n                },\n                \"author\": {\n                  \"type\": \"string\",\n                  \"description\": \"The author of the article\"\n                },\n                \"title\": {\n                  \"type\": \"string\",\n                  \"description\": \"The headline or title of the article.\"\n                },\n                \"description\": {\n                  \"type\": \"string\",\n                  \"description\": \"A description or snippet from the article.\"\n                },\n                \"url\": {\n                  \"type\": \"string\",\n                  \"description\": \"The direct URL to the article.\"\n                },\n                \"urlToImage\": {\n                  \"type\": \"string\",\n                  \"description\": \"The URL to a relevant image for the article.\"\n                },\n                \"publishedAt\": {\n                  \"type\": \"string\",\n                  \"description\": \"The date and time that the article was published, in UTC (+000)\"\n                },\n                \"content\": {\n                  \"type\": \"string\",\n                  \"description\": \"The unformatted content of the article, where available. This is truncated to 200 chars.\"\n                }\n              },\n              \"required\": [\n                \"title\"\n              ]\n            }\n          }\n        }\n      },\n      \"tool_provider\": {\n        \"provider_type\": \"http\",\n        \"url\": \"https://newsapi.org/v2/top-headlines\",\n        \"http_method\": \"GET\",\n        \"content_type\": \"application/json\",\n        \"auth\": {\n          \"auth_type\": \"api_key\",\n          \"api_key\": \"$NEWS_API_KEY\",\n          \"var_name\": \"X-Api-Key\"\n        }\n      }\n    }\n  ]\n}",
      "line_count": 252,
      "word_count": 959,
      "title": "Newsapi Manual.Json",
      "summary": "\"version\": \"1.0\", \"name\": \"everything_get\",",
      "key_terms": [
        "ISO",
        "page",
        "phrase",
        "search",
        "number",
        "chars",
        "error",
        "co",
        "If",
        "display",
        "either",
        "through",
        "Articles",
        "id",
        "format",
        "available",
        "searchIn",
        "It",
        "specified",
        "small"
      ],
      "timestamp": "2025-12-24T18:55:58.490729"
    }
  ],
  "timestamp": "2025-12-24T18:55:58.490729"
}